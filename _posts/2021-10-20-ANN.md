---
layout: post
title: Why are neural networks "universal approximators"?
subtitle: The Universal Approximation Theorem
cover-img: /assets/img/process1.jpg
thumbnail-img: /assets/img/vision.png
share-img: /assets/img/path.jpg
tags: 
- Machine Learning
- Math
---



A gentle start,

**Theorem 1 (Weierstrass Approximation Theorem).** Let $f:[a,b] \rightarrow\mathbb{R}$ be a continuous function, then there exists a polynomial $p$ on $[a,b]$ such that for any $\epsilon>0$, 



Now let's first simplify this problem a little bit, by restricting it to the case when $f \in C[0,1]$



**Definition 1 (Uniform Convergence).**    A sequence of functions {$f_n$}, $n=1,2,3...,$ converges uniformly on $E$ to

**Definition 2 (Uniform Continuity).**

If a function f on a compact set is continuous it's uniformly continuous

compactly supported

Convolution



Let's take a look at the proof in Baby Rudin(Principles of Mathematical Analysis, by Walter Rudin)



<div class="postcell post-layout--right">  
  <blockquote><strong>Theorem:</strong><p>If <span class="math-container">$f$</span> is a continuous complex function on <span class="math-container">$[a, b]$</span>, there exists a sequence of polynomials <span class="math-container">$P_n$</span> such that
<span class="math-container">$$ \lim_{n \to \infty} P_n(x) = f(x) $$</span>
    uniformly on <span class="math-container">$[a, b]$</span>. If <span class="math-container">$f$</span> is real, the <span class="math-container">$P_n$</span> may be taken real.</p></blockquote>
  <blockquote><p><strong>Proof:</strong></p>
    <p>We may assume, without loss of generality that <span class="math-container">$[a, b] = [0, 1]$</span>. We may also assume that <span class="math-container">$f(0) = f(1) = 0$</span>. For if the theorem is proved for this case, consider <span class="math-container">$$ g(x) = f(x) - f(0) - x [ f(1) - f(0) ] \qquad (0 \leq x \leq 1). $$</span> Here <span class="math-container">$g(0) = g(1) = 0$</span>, and if <span class="math-container">$g$</span> can be obtained as the limit of a uniformly convergent sequence of polynomials, it is clear that the same is true for <span class="math-container">$f$</span>, since <span class="math-container">$f-g$</span> is a polynomial.</p></blockquote>
  Hers is a further clarification on how proving the result on the interval [0, 1] would be sufficient to generalize to an arbitrary interval [a, b]. We define a function  <span class="math-container"> $$ g(x): [0,1] \to \mathbb{C} \\ f(x): [a,b] \to \mathbb{C} \\ g(x) = f((b-a)x+a)  $$ </span> and therefore we can convert it back <span class="math-container"> $$ f(x) = g(\frac{x-a}{b-a})$$</span> We can make a further modification that <span class="math-container"> $$ g(x) = f((b-a)x+a) - ((f(b)-f(a))x+f(a)) $$</span> then it's clear that <span class="math-container"> $$ g(0) = g(1) = 0, \\ $$ </span> and since $f-g$ is a polynomial, if we get a sequence of polynomials <span class="math-container"> $ \{P_n\} $ on $[0, 1]$ that converges uniformly to $g$, then rescaling and shifting $\{P_n\}$ with polynomials the same way we get $f$ from $g$ would get us a sequence of polynomials converging uniformly to $\:f.\\$ </span>
  <blockquote><p>Furthermore, we define <span class="math-container">$f(x)$</span> to be zero for <span class="math-container">$x$</span> outside <span class="math-container">$[0, 1]$</span>. Then <span class="math-container">$f$</span> is uniformly continuous on the whole line. <strong>[How is <span class="math-container">$f$</span> uniformly continuous? How to show this rigorously?]</strong></p></blockquote>
    <p>If $X$ is compact and $f:X\to \mathbb{C}$ is continuous, then $f$ is uniformly continuous. We also know that [0, 1], [a, b] are compact. </p>
<blockquote><p>We put
<span class="math-container">$$\tag{1}  Q_n(x) = c_n \left( 1- x^2 \right)^n \qquad (n = 1, 2, 3, \ldots), $$</span>
where <span class="math-container">$c_n$</span> is chosen so that
<span class="math-container">$$ \tag{2} \int_{-1}^1 Q_n(x) \ \mathrm{d} x = 1 \qquad (n = 1, 2, 3, \ldots). $$</span>
We need some information about the order of magnitude of <span class="math-container">$c_n$</span>. Since
<span class="math-container">$$ 
\begin{align} 
\int_{-1}^1 \left( 1-x^2 \right)^n \ \mathrm{d} x &amp;= 2 \int_0^1 \left( 1-x^2 \right)^n \ \mathrm{d} x \\
 &amp;\geq 2 \int_0^{1/\sqrt{n}} \left( 1-x^2 \right)^n \ \mathrm{d} x \\
&amp; \geq 2 \int_0^{1/\sqrt{n}} \left( 1- n x^2 \right) \ \mathrm{d} x \\
&amp;= \frac{4}{3 \sqrt{n} } \\
&amp;&gt; \frac{1}{ \sqrt{n} }, 
\end{align}
$$</span>
  it follows from (2) that <span class="math-container">$$ \tag{3} c_n &lt; \sqrt{n}. $$</span>
 The inequality <span class="math-container">$\left( 1-x^2 \right)^n \geq 1-nx^2$</span> which we used above is easily shown to be true by considering the function
<span class="math-container">$$ \left( 1- x^2 \right)^n - 1+nx^2 $$</span>
  which is zero at <span class="math-container">$x= 0$</span> and whose derivative is positive in <span class="math-container">$(0, 1)$. </span></p></blockquote>
  <p>
  You can also expand $\left( 1-x^2 \right)^n$ using binomial theorem 
    $$\begin{align*}
(1 - x^2)^n  &amp;= \sum_{k=0}^{n} (-1)^k \binom{n}{k} x^{2k} \\
&amp;= 1 - nx^2 + \text{higher-order terms,} 
    \end{align*}$$ where the sum of the higher-order terms is nonnegative </p>
<blockquote><p>For any <span class="math-container">$\delta &gt; 0$</span>, (3) implies
<span class="math-container">$$ \tag{4} Q_n(x) \leq \sqrt{n} \left( 1- \delta^2 \right)^n \qquad ( \delta \leq \lvert x \rvert \leq 1), $$</span>
  so that <span class="math-container">$Q_n \to 0$</span> uniformly in <span class="math-container">$\delta \leq \lvert x \rvert \leq 1$</span>. <strong>[Is this fact really needed in this proof?]</strong></p></blockquote>
 <p>Not explicitly mentioned but $\delta \in (0, 1)$, which implies $\\(1-\delta^2)^n \to 0$ $ \text{ exponentially, faster than $\sqrt{n}$,} \text{ therefore } \sqrt{n}(1-\delta^2)^n \to 0 $
  </p>
  <blockquote><p>Now set
    <span class="math-container">$$ \tag{5}  P_n(x) = \int_{-1}^1 f(x+t) Q_n (t) \ \mathrm{d} t \qquad (0 \leq x \leq 1). $$</span></p></blockquote>
  Notice that this is actually a convolution.<p>
  <strong>DEFINITION 4. (Convolution) </strong> $$(f \ast g)(t):=\int_{-\infty}^{\infty} f(\tau) g(t-\tau) d \tau$$ </p>
  <blockquote><p>
Our assumptions about <span class="math-container">$f$</span> show, by a simple change of variable, that
<span class="math-container">$$ P_n(x) = \int_{-x}^{1-x} f(x+t) Q_n(t) \ \mathrm{d} t = \int_0^1 f(t) Q_n(t-x) \ \mathrm{d} t, $$</span>
    and the last integral is clearly a polynomial in <span class="math-container">$x$</span>. <strong>[How to demonstrate this explicitly?]</strong> Thus <span class="math-container">$\left\{ P_n \right\}$</span> is a sequence of polynomials, which are real if <span class="math-container">$f$</span> is real.</p></blockquote>
  <blockquote><p>Given <span class="math-container">$\varepsilon &gt; 0$</span>, we choose <span class="math-container">$\delta &gt; 0$</span> such that <span class="math-container">$\lvert y-x \rvert &lt; \delta$</span> implies <span class="math-container">$$ \lvert f(y) - f(x) \rvert &lt; \frac{\varepsilon}{2}. $$</span></p></blockquote>
  This is by uniform continuity of $f\\$.
  <blockquote><p>
Let <span class="math-container">$M = \sup \lvert f(x) \rvert$</span>. Using (2), (4), and the fact that <span class="math-container">$Q_n(x) \geq 0$</span>, we see that for <span class="math-container">$0 \leq x \leq 1$</span>,
<span class="math-container">$$ 
\begin{align}
&amp; \ \ \  \left\lvert P_n(x) - f(x) \right\rvert \\ 
&amp;= \left\lvert \int_{-1}^1 [ f(x+t) - f(x) ] Q_n(t) \ \mathrm{d} t \right\rvert \\
&amp;\leq \int_{-1}^1 \lvert f(x+t) - f(x) \rvert Q_n(t) \ \mathrm{d} t \\
&amp;\leq 2M \int_{-1}^{-\delta} Q_n(t) \ \mathrm{d} t + \frac{\varepsilon}{2} \int_{-\delta}^\delta Q_n(t) \ \mathrm{d} t + 2 M \int_\delta^1 Q_n(t) \ \mathrm{d} t \\
&amp;\leq 4M \sqrt{n} \left( 1 - \delta^2 \right)^n + \frac{\varepsilon}{2} \\
&amp;&lt; \varepsilon
\end{align}
$$</span>
for all large enough <span class="math-container">$n$</span>, which proves the theorem.
    <span class="d-none">$\endgroup$</span></p></blockquote> 
  <p> 
    $$(f \ast g)(t):=\int_{-\infty}^{\infty} f(\tau) g(t-\tau) d \tau$$
  </p>
</div>





**Theorem 2 (Stone-Weierstrass Theorem).** 

Cybenko Theorem

Hornik TheoremUniversal Approximation Theorem for Deep Learning



---

*Marr, David, Vision: A Computational Investigation into the Human Representation and Processing of Visual Information (Cambridge, MA, 2010; online edn, MIT Press Scholarship Online, 22 Aug. 2013), https://doi.org/10.7551/mitpress/9780262514620.001.0001, accessed 19 Dec. 2021.*

Image credit

[Ellen Lupton](https://inosensiasharenagathahome.files.wordpress.com/2020/01/marrimg2.gif?w=594)



https://math.stackexchange.com/questions/2507841/theorem-7-26-in-baby-rudin-the-stone-weierstrass-theorem

